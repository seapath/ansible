# We need to restart nginx if it's running and know if gunicorn socket is present
- name: Populate service facts
  service_facts:
#- name: Print service facts
#  ansible.builtin.debug:
#    var: ansible_facts.services
- name: install vm-mgr http interface
  vars:
    vmmgrapi_certs_dir: "/var/local/vmmgrapi/certs"
  block:
    - name: create vm-mgr api certs folder
      file:
        path: "{{ vmmgrapi_certs_dir }}"
        state: directory
        mode: 0755

    - name: upload cert/key if provided
      copy:
        src: "{{ item }}"
        dest: "{{ vmmgrapi_certs_dir }}/{{ item }}"
        mode: '0644'
      with_items:
        - "{{ vmmgr_http_tls_crt_path }}"
        - "{{ vmmgr_http_tls_key_path }}"
      when:
        - vmmgr_http_tls_crt_path is defined
        - vmmgr_http_tls_key_path is defined

    - name: create certificat / key if not provided
      command: openssl req -x509 -nodes -days 9125 -newkey rsa:4096 -subj "/C=FR/ST=seapath/L=seapath/O=seapath/OU=seapath/CN=seapath" -keyout "{{ vmmgrapi_certs_dir }}/seapath.key" -out "{{ vmmgrapi_certs_dir }}/seapath.crt"
      args:
        creates: "{{ item }}"
      with_items:
        - "{{ vmmgrapi_certs_dir }}/seapath.crt"
        - "{{ vmmgrapi_certs_dir }}/seapath.key"

    - name: Correct certificates rights
      file:
        path: "{{ vmmgrapi_certs_dir }}/{{ item }}"
        mode: 0644
      loop:
        - "seapath.crt"

    - name: Correct private keys rights
      file:
        path: "{{ vmmgrapi_certs_dir }}/{{ item }}"
        mode: 0640
      loop:
        - "seapath.key"

    - name: Check permission on authentication file
      ansible.builtin.file:
        path: "{{ vmmgr_http_local_auth_file }}"
        owner: www-data
        group: www-data
        mode: '0600'
        state: touch
      when: vmmgr_http_local_auth_file is defined

    - name: Copy nginx.conf
      template:
        src: ../src/debian/vmmgrapi/nginx.conf.j2
        dest: /etc/nginx/nginx.conf
        mode: '0600'
      register: nginx_conf

    - name: restart nginx if needed
      ansible.builtin.systemd:
        name: nginx.service
        enabled: no
        state: stopped
      when:
        - nginx_conf.changed
        - services['nginx.service']['state'] == "running"

    - name: Copy vmmgrapi files
      ansible.builtin.copy:
        src: ../src/debian/vmmgrapi/{{ item }}
        dest: /var/local/vmmgrapi/{{ item }}
        mode: '0644'
      with_items:
        - wsgi.py

    - name: Copy vmmgrapi systemd files
      ansible.builtin.copy:
        src: ../src/debian/vmmgrapi/{{ item }}
        dest: /etc/systemd/system/{{ item }}
        mode: '0644'
      with_items:
        - gunicorn.socket
        - gunicorn.service
      register: vmmgrapi_systemd

    - name: daemon-reload vmmgrapi
      ansible.builtin.service:
        daemon_reload: yes
      when: vmmgrapi_systemd.changed

    - name: restart gunicorn.socket if needed
      ansible.builtin.systemd:
        name: gunicorn.socket
        enabled: yes
        state: restarted
      when: vmmgrapi_systemd.changed

    - name: start and enable gunicorn.socket
      ansible.builtin.systemd:
        name: gunicorn.socket
        enabled: yes
        state: started

  when: enable_vmmgr_http_api is defined and enable_vmmgr_http_api is true

- name: disable gunicorn.socket if http flask api is not enabled
  ansible.builtin.systemd:
    name: gunicorn.socket
    enabled: no
    state: stopped
  when:
    - enable_vmmgr_http_api is not defined or enable_vmmgr_http_api is false
    - services['gunicorn.socket'] is defined

- name: disable nginx.service all the time, if it exists
  ansible.builtin.systemd:
    name: nginx.service
    enabled: no
  when:
    - services['nginx.service'] is defined

- name: disable gunicorn.service all the time, if it exists
  ansible.builtin.systemd:
    name: gunicorn.service
    enabled: no
  when:
    - services['gunicorn.service'] is defined

- name: Copy sysctl rules
  ansible.builtin.copy:
    src: "{{ item }}"
    dest: /etc/sysctl.d/{{ item }}
    mode: '0644'
  with_items:
    - 00-bridge_nf_call.conf
  register: sysctl1

- name: Add sysctl conf from inventory (extra_sysctl_physical_machines)
  ansible.builtin.copy:
    dest: /etc/sysctl.d/00-seapathextra_physicalmachines.conf
    mode: '0644'
    content: "{{ extra_sysctl_physical_machines }}"
  when: extra_sysctl_physical_machines is defined
  register: sysctl2

- name: restart systemd-sysctl if needed
  ansible.builtin.systemd:
    name: systemd-sysctl.service
    state: restarted
  when: sysctl1.changed or sysctl2.changed

- name: create src folder on hosts
  file:
    path: /tmp/src
    state: directory
    mode: '0755'

- name: temp fix for synchronize to force evaluate variables
  set_fact:
    ansible_host: "{{ ansible_host }}"

- name: deploy vm_manager
  include_role:
    name: deploy_vm_manager

- name: deploy python3-setup-ovs
  include_role:
    name: deploy_python3_setup_ovs

- name: Copy consolevm.sh
  template:
    src: consolevm.sh.j2
    dest: /usr/local/bin/consolevm
    mode: '0755'

- name: create /usr/lib/ocf/resource.d/seapath on hosts
  file:
    path: /usr/lib/ocf/resource.d/seapath
    state: directory
    mode: '0755'

- name: Copy Pacemaker Seapath Resource-Agent files
  ansible.posix.synchronize:
    src: pacemaker_ra/
    dest: /usr/lib/ocf/resource.d/seapath/
    rsync_opts:
    - "--chmod=F755"
    - "--chown=root:root"

- name: Copy chrony-wait.service
  template:
    src: chrony-wait.service.j2
    dest: /etc/systemd/system/chrony-wait.service
    owner: root
    group: root
    mode: '0644'
  register: chronywait
- name: daemon-reload chrony-wait.service
  ansible.builtin.service:
    daemon_reload: yes
  when: chronywait.changed
- name: enable chrony-wait.service
  ansible.builtin.systemd:
    name: chrony-wait.service
    enabled: yes

- name: Create pacemaker.service.d directory
  file:
    path: /etc/systemd/system/pacemaker.service.d/
    state: directory
    owner: root
    group: root
    mode: 0755
- name: Copy pacemaker.service drop-in
  template:
    src: pacemaker_override.conf.j2
    dest: /etc/systemd/system/pacemaker.service.d/override.conf
    owner: root
    group: root
    mode: 0644
  notify: daemon-reload
  register: pacemaker_corosync
- name: Get Pacemaker service Status
  ansible.builtin.systemd:
    name: "pacemaker.service"
  register: pacemaker_service_status
- name: disable pacemaker (reinstall step 1/2)
  ansible.builtin.systemd:
    name: pacemaker.service
    enabled: no
  when: pacemaker_corosync.changed and pacemaker_service_status.status.UnitFileState == "enabled"
- name: enable pacemaker (reinstall step 2/2)
  ansible.builtin.systemd:
    name: pacemaker.service
    enabled: yes
  when: pacemaker_corosync.changed and pacemaker_service_status.status.UnitFileState == "enabled"

- name: Add extra modules to the kernel
  lineinfile:
    dest: /etc/modules
    state: present
    regexp: "^{{ item }}$"
    line: "{{ item }}"
  with_items: "{{ extra_kernel_modules | default([]) }}"

- name: Add admin user to libvirt group
  user:
    name: "{{ admin_user }}"
    groups: libvirt
    append: yes

- name: Creating libvirt user with libvirtd permissions
  user: name=libvirt
    group=libvirt
    shell=/bin/false

- name: add br_netfilter to /etc/modules
  lineinfile:
    dest: /etc/modules
    state: present
    regexp: '^br_netfilter$'
    line: 'br_netfilter'
- name: add raid6_pq to /etc/modules
  lineinfile:
    dest: /etc/modules
    state: present
    regexp: '^raid6_pq$'
    line: 'raid6_pq'

- name: Copy apparmor libvirt-qemu rules
  ansible.builtin.copy:
    src: etc_apparmor.d_abstractions_libvirt-qemu.conf
    dest: /etc/apparmor.d/abstractions/libvirt-qemu
    mode: '0644'

- name: lineinfile in hosts file for logstash-seapath
  lineinfile:
    dest: /etc/hosts
    regexp: '.* logstash-seapath$'
    line: "{{ logstash_server_ip }} logstash-seapath"
    state: present
  when: logstash_server_ip is defined

- name: Make libvirt use the "machine-id" way to determine host UUID
  lineinfile:
    dest: /etc/libvirt/libvirtd.conf
    regexp: "^#?host_uuid_source ="
    line: "host_uuid_source = \"machine-id\""
    state: present
- name: restart libvirtd
  ansible.builtin.systemd:
    name: libvirtd.service
    state: restarted

- name: enable docker.service
  ansible.builtin.systemd:
    name: docker.service
- name: "add initramfs-tools scripts: script file (LVM rebooter and log handling)"
  ansible.builtin.copy:
    src: initramfs-tools/scripts/
    dest: /etc/initramfs-tools/scripts/
    mode: '0755'
  register: initramfs_tools_scripts

- name: "get the /var/log/ device"
  command: "findmnt -n -o SOURCE --target /var/log"
  register: varlog_dev

- name: "set_fact /var/log/ device"
  set_fact:
    lvm_rebooter_log_device: "{{ varlog_dev.stdout }}"

- name: "get the /var/log/ relative path"
  shell: "realpath --relative-to=$(findmnt -n -o TARGET --target /var/log/) /var/log"
  register: varlog_path

- name: "set_fact /var/log/ relative path"
  set_fact:
    lvm_rebooter_log_path: "{{ varlog_path.stdout }}"

- name: "Copy rebooter.conf"
  template:
    src: initramfs-tools/conf.d/rebooter.conf.j2
    dest: /etc/initramfs-tools/conf.d/rebooter.conf

- name: "configure initramfs-tools to use busybox"
  lineinfile:
    dest: /etc/initramfs-tools/initramfs.conf
    regexp: "^#?BUSYBOX="
    line: "BUSYBOX=y"
    state: present
  register: initramfs_busybox

- name: "add udev rules for lvm2 limitation"
  ansible.builtin.copy:
    src: 69-lvm.rules
    dest: /etc/udev/rules.d/69-lvm.rules
    mode: '0644'
  when: ansible_distribution == 'Debian' and ansible_distribution_version | int >= 12
  register: udevlvm

- name: "rebuild initramfs if necessary"
  command:
    cmd: /usr/sbin/update-initramfs -u
  when: udevlvm.changed or initramfs_tools_scripts.changed or initramfs_busybox.changed

- name: "add rbd type to lvm.conf"
  ansible.builtin.lineinfile:
    path: /etc/lvm/lvm.conf
    insertafter: 'devices {'
    line: "        types = [ \"rbd\", 1024 ]"
    state: present


