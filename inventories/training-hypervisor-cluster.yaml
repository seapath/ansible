# This inventory describes a SEAPATH cluster with two hypervisors and one observer.
# It contains all required variables to configure and run your cluster.
# Replace all the TODOs to fit your physical machines.
# More informations on SEAPATH Wiki: https://lf-energy.atlassian.net/wiki/x/lIblAQ

---
cluster_machines:
  children:
    hypervisors:
      hosts:
        hypervisor1:
          # TODO : Replace the variable by your IP or interfaces

          # Admin network settings
          ansible_host: 192.168.2.31
          network_interface: enp3s0

          # Cluster network settings
          team0_0: "enp0s20f0u1u2u1"
          team0_1: "enp0s20f0u1u2u2"
          cluster_ip_addr: "192.168.11.1"
          cluster_next_ip_addr : "192.168.11.2"
          cluster_previous_ip_addr : "192.168.11.3"

          # PTP configuration.
          # Optional, remove if the machine is not synchronised with PTP
          ptp_interface: "enp3s0"

        hypervisor2:
          # TODO : Replace the variables by your IP or interfaces

          # Admin network settings
          ansible_host: 192.168.2.32
          network_interface: enp3s0

          # Cluster network settings
          team0_0: "enp0s20f0u1u2u1"
          team0_1: "enp0s20f0u1u2u2"
          cluster_ip_addr: "192.168.11.2"
          cluster_next_ip_addr : "192.168.11.3"
          cluster_previous_ip_addr :  "192.168.11.1"

          # PTP configuration.
          # Optional, remove if the machine is not synchronised with PTP
          ptp_interface: "enp3s0"

      vars:
        livemigration_user: livemigration
        isolcpus: "4-N" # TODO : Put the list of cpus to isolate.
          # This variable is only used on Debian.
          # On Yocto, it is configured in yocto-bsp

    observers:
      hosts:
        observer:
          # TODO : Replace the variables by your IP or interfaces

          # Admin network settings
          ansible_host: 192.168.2.33
          network_interface: enp3s0

          # Cluster network settings
          team0_0: "enp0s20f0u1u2"
          team0_1: "enp2s0"
          cluster_ip_addr: "192.168.11.3"
          cluster_next_ip_addr : "192.168.11.1"
          cluster_previous_ip_addr :  "192.168.11.2"
          br_rstp_priority: 12288 # Do not modify
            # This value is needed only on third machine for the RSTP to work

          # PTP configuration.
          ptp_interface: "enp3s0"

  vars:
    # Ansible vars
    ansible_remote_tmp: /tmp/.ansible/tmp
    ansible_user: ansible # TODO: Put the name of your ansible user
    # By default, this user is "ansible" on Debian and "admin" on Yocto

    # Debian specific, remove if you use Yocto
    admin_user: admin

    # Main network configuration
    gateway_addr: "" # TODO : Put your gatway address
    ip_addr: "{{ ansible_host }}"
    apply_network_config: true
    # systemd-networkd is used by default to configure the network
    # netplan can also be used to sum up complex network in one yaml file
    # See the wiki for more informations : TODO put link

    ignored_bridges:
      - "team0"

    # Hardening (Debian only)
    # TODO : Put the password hash for the grub password
    # It can be generated with the following command: grub-mkpasswd-pbkdf2
    grub_password: grub.pbkdf2.sha512.10000.666FF16D5587509B2B3340B2388CB798BEF9553A9666CECA6282E0D822C1529F94AF693CC6738C1F757B868D8090F24FD48D8F56486C70C545D559CB4BAAAA3E.9718E767036BDB71CC1B82BCFC906610F8772DD4757F6F075D82A23E70DA46FBED372A3E5143E5C2D40AA888C6B884E4AA437488D82008383C54ED79D68A42CF

    # PTP should E2E in cluster if the switch doesn't have a TC
    timemaster_ptp_delay_mechanism: "E2E"

# ------------------------------------------------------------------------------
# ------------------- Ceph configuration part ----------------------------------
# ------------------------------------------------------------------------------

# This part contains SEAPATH default ceph configuration
# Change only the TODOs, Do not change the other variables, unless you know
# exactly what you are doing.
    ceph_origin: distro
    cluster_network: "192.168.11.0/24" # TODO : Replace by the IP range of your cluster
    public_network: "{{ cluster_network }}"
    monitor_address: "{{ cluster_ip_addr }}"
    configure_firewall: false
    ntp_service_enabled: false
    dashboard_enabled: false
    ceph_conf_overrides:
      global:
        osd_pool_default_size: "{{ groups['hypervisors'] | length }}"
        osd_pool_default_min_size: 1 # TODO
          # Set to the minimum number of osd needed to run the cluster
          # You probably want 2 in case of a three hypervisors configuration
          # And 1 in case of a two hypervisors and one observer
        osd_pool_default_pg_num: 128
        osd_pool_default_pgp_num: 128
        osd_crush_chooseleaf_type: 1
        mon_osd_min_down_reporters: 1
      mon:
        auth_allow_insecure_global_id_reclaim: false
      osd:
        osd memory target: 8076326604

# Ceph monitor. All machines in the cluster must be part of mons groups
mons:
  hosts:
    hypervisor1:
    hypervisor2:
    observer:

# Ceph OSD. Machines that will be used as OSDs (which will store data)
osds:
  hosts:
    hypervisor1:
    hypervisor2:
  vars:
    ceph_osd_disk: "/dev/disk/by-path/pci-0000:00:17.0-ata-1.0"
      # Set this to the path of the disk that will contains ceph data.
      # The path can be found in "/dev/disk/by-path/"
    devices: "{{ ceph_osd_disk }}"

# Ceph clients. All machines in the cluster must be part of clients groups
clients:
  hosts:
    hypervisor1:
    hypervisor2:
    observer:
  vars:
    user_config: true
    rbd:
      name: "rbd"
      application: "rbd"
      pg_autoscale_mode: on
      target_size_ratio: 1
    pools:
      - "{{ rbd }}"
    keys:
      - name: client.libvirt
        caps:
          mon: 'profile rbd, allow command "osd blacklist"'
          osd: "allow class-read object_prefix rbd_children, profile rbd pool=rbd"
        mode: "{{ ceph_keyring_permissions }}"

# ------------------------------------------------------------------------------
# ----------------------- Empty groups, prevent warnings -----------------------
# ------------------------------------------------------------------------------
grafana-server:
iscsigws:
iscsi-gws:
mdss:
mgrs:
nfss:
rbdmirrors:
rgwloadbalancers:
rgws:
standalone_machine:

all:
  vars:
    ansible_ssh_private_key_file: ~/.ssh/seapath-training-key
    ansible_connection: ssh
    ansible_python_interpreter: /usr/bin/python3
    ansible_ssh_common_args: '-o StrictHostKeyChecking=no'
    ansible_ssh_private_key_file: /home/seapath/seapath/labs/seapath-training-key
...
